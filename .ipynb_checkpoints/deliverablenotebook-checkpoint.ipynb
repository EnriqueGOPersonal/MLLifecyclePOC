{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HIfRVXDKq4f9"
   },
   "source": [
    "# Credijusto Data Scientist Challenge ðŸ’»ðŸ’°ðŸš€\n",
    "\n",
    "## Dataset description.\n",
    "\n",
    "#### 1) Personal [data table]\n",
    "- **client_id**\n",
    "    - key to job table\n",
    "    - key to bank table\n",
    "    - key to transactional data table\n",
    "- name\n",
    "- address\n",
    "- phone_number\n",
    "- email_domain\n",
    "- smoker\n",
    "- is_married\n",
    "- car_licence_plate\n",
    "- age\n",
    "- number_of_children\n",
    "- years_of_education\n",
    "- has_criminal_records\n",
    "\n",
    "#### 2. Job [data table]\n",
    "- **client_id**\n",
    "    - key to personal table\n",
    "    - key to bank table\n",
    "    - key to transactional data table\n",
    "- company\n",
    "- phone_number\n",
    "- address\n",
    "- email_domain\n",
    "- current_job\n",
    "- car_licence_plate\n",
    "- years_in_current_job\n",
    "- salary\n",
    "\n",
    "#### 3. Bank [data table]\n",
    "- **client_id**\n",
    "    - key to personal table\n",
    "    - key to job table\n",
    "    - key to transactional data table\n",
    "- account_id\n",
    "    - key to transactional data table\n",
    "- number_of_credit_cards\n",
    "- number_logs_per_day\n",
    "- number_secret_keys_requested\n",
    "- credit_card_number\n",
    "- credit_card_expire\n",
    "- credit_card_provider\n",
    "- credit_score\n",
    "- first_credit_card_application_date\n",
    "- last_credit_card_application_date\n",
    "- **defaulted_loan**\n",
    "    - Variable to predit\n",
    "\n",
    "#### 4. Transactional [data table]\n",
    "- **transaction_id**\n",
    "- **account_id**\n",
    "    - key to bank table\n",
    "- **client_id**\n",
    "    - key to personal table\n",
    "    - key to job table\n",
    "    - key to bank data table\n",
    "- duration_minutes\n",
    "- amount\n",
    "- type\n",
    "- date\n",
    "\n",
    "## Business question\n",
    "\n",
    "#### Background\n",
    "\n",
    "1. **Only the training set bank data table has the column defaulted_loan** which has two different outcomes:\n",
    "    - True\n",
    "        - Client defaulted (did not pay credit).\n",
    "        - This is the *Positive class*\n",
    "    - False\n",
    "        - Client is OK (did pay credit).\n",
    "        - This is the *Negative class*\n",
    "2. You need to make a predictive model to **make predictions of the feature defaulted_loan on the test dataset**.\n",
    "3. **The evaluation of this challenge relies only on the prediction scores on test dataset**.\n",
    "    - Choose wisely the evaluation metric for this challenge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition\n",
    "\n",
    "Lenders provide loans to borrowers in exchange for the promise of repayment with interest. That means the lender only makes profit (interest) if the borrower pays off the loan. However, if he/she doesnâ€™t repay the loan, then the lender loses money.\n",
    "\n",
    "Therefore the lending industry is based in the answers of two critical questions: \n",
    "\n",
    "1) How risky is the borrower?\n",
    "\n",
    "2) Given the borrowerâ€™s risk, should we lend him/her? \n",
    "\n",
    "The answer to the first question determines the interest rate the borrower would have. Interest rate measures among other things (such as time value of money) the riskness of the borrower, i.e. the riskier the borrower, the higher the interest rate. With interest rate in mind, we can then determine if the borrower is eligible for the loan.\n",
    "\n",
    "\"Predicting Loan Repayment\", Imad Dabbura https://towardsdatascience.com/predicting-loan-repayment-5df4e0023e92 [1]\n",
    "\n",
    "As stated in the Business question, for our purposes we would only predict the answer of the question 1.\n",
    "\n",
    "## The importance of predicting right the borrower's riskness\n",
    "\n",
    "bla bla...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbky0Jhpq4gA"
   },
   "source": [
    "# Set working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiT_kq-wq4gA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maumt\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\maumt\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle, safe_indexing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "import io\n",
    "import matplotlib as plt\n",
    "# Run this to install not common libraries\n",
    "#!pip install eli5\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTKAWuyLq4gD"
   },
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CMTr44dq4gE"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'train': {\n",
    "        'personal': pd.read_csv('data/client_personal_train.csv'),\n",
    "        'job': pd.read_csv('data/client_job_train.csv'),\n",
    "        'bank_data': pd.read_csv('data/client_bank_data_train.csv'),\n",
    "        'transactional_data': pd.read_csv('data/client_transactional_data_train.csv')      \n",
    "    },\n",
    "    'test': {\n",
    "        'personal': pd.read_csv('data/client_personal_test.csv'),\n",
    "        'job': pd.read_csv('data/client_job_test.csv'),\n",
    "        'bank_data': pd.read_csv('data/client_bank_data_test.csv'),\n",
    "        'transactional_data': pd.read_csv('data/client_transactional_data_test.csv')\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCIG6OSXq4gG"
   },
   "source": [
    "## Train Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hk0no8Crq4gH"
   },
   "source": [
    "### 1 - **Checking datasets dimesions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XwSoYDrOq4gI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: personal | Dataset dimension (rows, cols): (68992, 12)\n",
      "Dataset: job | Dataset dimension (rows, cols): (68992, 9)\n",
      "Dataset: bank_data | Dataset dimension (rows, cols): (68992, 12)\n",
      "Dataset: transactional_data | Dataset dimension (rows, cols): (1517581, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Dataset: ' + x + ' | Dataset dimension (rows, cols): ' + str(data['train'][x].shape)) for x in data['train'].keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sJiq992q4gM"
   },
   "source": [
    "### 2 - **Checking Row example values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7G2nPwKq4gN"
   },
   "source": [
    "#### 1) Personal datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfmmE8E0q4gO",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_married</th>\n",
       "      <th>age</th>\n",
       "      <th>name</th>\n",
       "      <th>number_of_children</th>\n",
       "      <th>car_licence_plate</th>\n",
       "      <th>address</th>\n",
       "      <th>has_criminal_records</th>\n",
       "      <th>smoker</th>\n",
       "      <th>years_of_education</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>client_id</th>\n",
       "      <th>email_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>Joel Herrera</td>\n",
       "      <td>2</td>\n",
       "      <td>8R 3A5NOQ</td>\n",
       "      <td>0550 Tanya Ferry\\nFergusonport, IA 41180</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>(444)128-8524x089</td>\n",
       "      <td>MUMR3875397452595</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>Justin Burgess</td>\n",
       "      <td>3</td>\n",
       "      <td>QIE 2694</td>\n",
       "      <td>080 Emily Springs Suite 947\\nSerranostad, AZ 7...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>419-736-1369x7810</td>\n",
       "      <td>LNFC4821269126830</td>\n",
       "      <td>hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>Samantha Brown</td>\n",
       "      <td>3</td>\n",
       "      <td>6KV R45</td>\n",
       "      <td>59687 Alexander Walk\\nEast David, AZ 21330</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>1209272743</td>\n",
       "      <td>PIGP5747447418648</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>Jason Ware</td>\n",
       "      <td>1</td>\n",
       "      <td>YL9 0751</td>\n",
       "      <td>13474 Flores Mall Suite 952\\nNorth Erinfort, N...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>(282)819-4842</td>\n",
       "      <td>MDZY2927886938414</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>Ronald Hoffman</td>\n",
       "      <td>3</td>\n",
       "      <td>LPG 832</td>\n",
       "      <td>31878 Heather Rapids Suite 933\\nNorth Marie, A...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>142-489-3506</td>\n",
       "      <td>WETM2827630477279</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_married  age            name  number_of_children car_licence_plate  \\\n",
       "0       False   31    Joel Herrera                   2         8R 3A5NOQ   \n",
       "1       False   26  Justin Burgess                   3          QIE 2694   \n",
       "2        True   29  Samantha Brown                   3           6KV R45   \n",
       "3        True   34      Jason Ware                   1          YL9 0751   \n",
       "4        True   33  Ronald Hoffman                   3           LPG 832   \n",
       "\n",
       "                                             address  has_criminal_records  \\\n",
       "0           0550 Tanya Ferry\\nFergusonport, IA 41180                 False   \n",
       "1  080 Emily Springs Suite 947\\nSerranostad, AZ 7...                  True   \n",
       "2         59687 Alexander Walk\\nEast David, AZ 21330                 False   \n",
       "3  13474 Flores Mall Suite 952\\nNorth Erinfort, N...                 False   \n",
       "4  31878 Heather Rapids Suite 933\\nNorth Marie, A...                 False   \n",
       "\n",
       "   smoker  years_of_education       phone_number          client_id  \\\n",
       "0    True                  14  (444)128-8524x089  MUMR3875397452595   \n",
       "1    True                  17  419-736-1369x7810  LNFC4821269126830   \n",
       "2    True                  17         1209272743  PIGP5747447418648   \n",
       "3   False                   8      (282)819-4842  MDZY2927886938414   \n",
       "4    True                  13       142-489-3506  WETM2827630477279   \n",
       "\n",
       "  email_domain  \n",
       "0    yahoo.com  \n",
       "1  hotmail.com  \n",
       "2    gmail.com  \n",
       "3    gmail.com  \n",
       "4    yahoo.com  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['personal'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wkDzxTWq4gR"
   },
   "source": [
    "**Note**:\n",
    "* Although it is currently not possible, with the help of an hypothetical additional  \"*common_names_dataset*\" for female and male individuals, genre information can be extracted from _name_ column for future analysis.\n",
    "* Depending on quality of the information contained in the column _address_ , geographical data might be useful for future analysis. For simplicity we won't do it in this notebook.\n",
    "* *car_licence_plate*, *phone_number* and *email_domain* columns seem to have no useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Okav9PR5q4gS"
   },
   "source": [
    "#### 2) Job datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSaz72tHq4gU",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_in_current_job</th>\n",
       "      <th>client_id</th>\n",
       "      <th>salary</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>car_licence_plate</th>\n",
       "      <th>company</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>address</th>\n",
       "      <th>current_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>LCQQ3834995242554</td>\n",
       "      <td>6626</td>\n",
       "      <td>+1-870-455-1656</td>\n",
       "      <td>AUJ 311</td>\n",
       "      <td>Smith, Walton and Smith</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>Unit 4250 Box 5536\\nDPO AE 73809</td>\n",
       "      <td>Retail banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>BRCD7200842828050</td>\n",
       "      <td>8343</td>\n",
       "      <td>519-526-9913x6540</td>\n",
       "      <td>223R5</td>\n",
       "      <td>Santos, Wilson and Hampton</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>PSC 4581, Box 0827\\nAPO AE 63527</td>\n",
       "      <td>Intelligence analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>RSAA3840744969487</td>\n",
       "      <td>6728</td>\n",
       "      <td>5360419904</td>\n",
       "      <td>NXV D21</td>\n",
       "      <td>Adkins-Mcneil</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>1036 Susan Roads\\nEast Christophermouth, PA 99481</td>\n",
       "      <td>Multimedia specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>KZWB7793929593940</td>\n",
       "      <td>7653</td>\n",
       "      <td>+1-245-845-9876x1778</td>\n",
       "      <td>165 6EL</td>\n",
       "      <td>Aguilar-Paul</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>72107 Hernandez Crossing Suite 699\\nKnappstad,...</td>\n",
       "      <td>Development worker, community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>TETJ4085914615232</td>\n",
       "      <td>8437</td>\n",
       "      <td>739-916-7742</td>\n",
       "      <td>919 8NG</td>\n",
       "      <td>Jensen PLC</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>554 Flores Port\\nKevinshire, FL 60356</td>\n",
       "      <td>Investment analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   years_in_current_job          client_id  salary          phone_number  \\\n",
       "0                    10  LCQQ3834995242554    6626       +1-870-455-1656   \n",
       "1                    10  BRCD7200842828050    8343     519-526-9913x6540   \n",
       "2                    15  RSAA3840744969487    6728            5360419904   \n",
       "3                     8  KZWB7793929593940    7653  +1-245-845-9876x1778   \n",
       "4                    11  TETJ4085914615232    8437          739-916-7742   \n",
       "\n",
       "  car_licence_plate                     company email_domain  \\\n",
       "0           AUJ 311     Smith, Walton and Smith  hotmail.com   \n",
       "1             223R5  Santos, Wilson and Hampton    yahoo.com   \n",
       "2           NXV D21               Adkins-Mcneil    yahoo.com   \n",
       "3           165 6EL                Aguilar-Paul  hotmail.com   \n",
       "4           919 8NG                  Jensen PLC  hotmail.com   \n",
       "\n",
       "                                             address  \\\n",
       "0                   Unit 4250 Box 5536\\nDPO AE 73809   \n",
       "1                   PSC 4581, Box 0827\\nAPO AE 63527   \n",
       "2  1036 Susan Roads\\nEast Christophermouth, PA 99481   \n",
       "3  72107 Hernandez Crossing Suite 699\\nKnappstad,...   \n",
       "4              554 Flores Port\\nKevinshire, FL 60356   \n",
       "\n",
       "                     current_job  \n",
       "0                  Retail banker  \n",
       "1           Intelligence analyst  \n",
       "2          Multimedia specialist  \n",
       "3  Development worker, community  \n",
       "4             Investment analyst  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['job'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACTeSJNZq4gX"
   },
   "source": [
    "**Note**:\n",
    "* Depending on quality of the information contained in the column _address_ , geographical data might be useful for future analysis.\n",
    "* *car_licence_plate*, *phone_number* and *email_domain* columns seem to have no useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGBscRu9q4gZ"
   },
   "source": [
    "#### 3) Bank datatable\n",
    "- Notice that this is the table that contains variable to predict: **defaulted_loan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAIb-rJRq4ga",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_secret_keys_requested</th>\n",
       "      <th>credit_card_provider</th>\n",
       "      <th>number_logs_per_day</th>\n",
       "      <th>first_credit_card_application_date</th>\n",
       "      <th>last_credit_card_application_date</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>number_of_credit_cards</th>\n",
       "      <th>account_id</th>\n",
       "      <th>credit_card_expire</th>\n",
       "      <th>client_id</th>\n",
       "      <th>defaulted_loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>VISA 16 digit</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-10-06 17:58:56</td>\n",
       "      <td>2015-10-31 02:43:10</td>\n",
       "      <td>814</td>\n",
       "      <td>3596118963565100</td>\n",
       "      <td>2</td>\n",
       "      <td>RSGD4569350483260</td>\n",
       "      <td>07/27</td>\n",
       "      <td>ZFUU9069197973171</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VISA 16 digit</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-07-18 09:22:24</td>\n",
       "      <td>2017-04-06 23:21:34</td>\n",
       "      <td>835</td>\n",
       "      <td>4036708575533672</td>\n",
       "      <td>2</td>\n",
       "      <td>UNKI9301808547977</td>\n",
       "      <td>04/26</td>\n",
       "      <td>EZZZ2264498911884</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-04 06:00:26</td>\n",
       "      <td>2015-10-06 07:11:36</td>\n",
       "      <td>1040</td>\n",
       "      <td>5187829527586586</td>\n",
       "      <td>3</td>\n",
       "      <td>PREO5042440106050</td>\n",
       "      <td>09/24</td>\n",
       "      <td>HTIX3716125146816</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mastercard</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-05-12 21:45:03</td>\n",
       "      <td>2016-01-01 23:51:21</td>\n",
       "      <td>808</td>\n",
       "      <td>4069649723930</td>\n",
       "      <td>2</td>\n",
       "      <td>YFMX9024672103664</td>\n",
       "      <td>04/28</td>\n",
       "      <td>WVDK6716021964941</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-06-24 23:49:50</td>\n",
       "      <td>2018-08-12 03:12:38</td>\n",
       "      <td>523</td>\n",
       "      <td>4511324297912</td>\n",
       "      <td>3</td>\n",
       "      <td>VXZA6446374802774</td>\n",
       "      <td>08/24</td>\n",
       "      <td>GPHF8397791795583</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_secret_keys_requested credit_card_provider  number_logs_per_day  \\\n",
       "0                             1        VISA 16 digit                    3   \n",
       "1                             1        VISA 16 digit                    3   \n",
       "2                             1         JCB 16 digit                    2   \n",
       "3                             1           Mastercard                    3   \n",
       "4                             1         JCB 16 digit                    3   \n",
       "\n",
       "  first_credit_card_application_date last_credit_card_application_date  \\\n",
       "0                2011-10-06 17:58:56               2015-10-31 02:43:10   \n",
       "1                2017-07-18 09:22:24               2017-04-06 23:21:34   \n",
       "2                2017-08-04 06:00:26               2015-10-06 07:11:36   \n",
       "3                2017-05-12 21:45:03               2016-01-01 23:51:21   \n",
       "4                2017-06-24 23:49:50               2018-08-12 03:12:38   \n",
       "\n",
       "   credit_score  credit_card_number  number_of_credit_cards  \\\n",
       "0           814    3596118963565100                       2   \n",
       "1           835    4036708575533672                       2   \n",
       "2          1040    5187829527586586                       3   \n",
       "3           808       4069649723930                       2   \n",
       "4           523       4511324297912                       3   \n",
       "\n",
       "          account_id credit_card_expire          client_id  defaulted_loan  \n",
       "0  RSGD4569350483260              07/27  ZFUU9069197973171           False  \n",
       "1  UNKI9301808547977              04/26  EZZZ2264498911884           False  \n",
       "2  PREO5042440106050              09/24  HTIX3716125146816           False  \n",
       "3  YFMX9024672103664              04/28  WVDK6716021964941           False  \n",
       "4  VXZA6446374802774              08/24  GPHF8397791795583           False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['bank_data'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_xucwOwq4gc"
   },
   "source": [
    "**Note**:\n",
    "* Depending on quality of the information contained in the column _address_ , geographical data might be useful for future analysis.\n",
    "* *credit_card_number*, *phone_number* and *email_domain* columns seem to have no useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKgBupx4q4gd"
   },
   "source": [
    "#### 4) Bank transactions datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7L3AMMbq4ge",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>amount</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BIGS2655386520335</td>\n",
       "      <td>SQWI6088247113041</td>\n",
       "      <td>UUJG9330648144708</td>\n",
       "      <td>2018-08-21 12:59:47</td>\n",
       "      <td>10</td>\n",
       "      <td>238</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BVVC7567878745629</td>\n",
       "      <td>EVEL6951619336672</td>\n",
       "      <td>PZWH9597088886612</td>\n",
       "      <td>2018-07-28 21:21:51</td>\n",
       "      <td>16</td>\n",
       "      <td>387</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>UUSU6640167293035</td>\n",
       "      <td>MLFH5670327424978</td>\n",
       "      <td>JHZB9470931550704</td>\n",
       "      <td>2018-09-01 00:44:48</td>\n",
       "      <td>12</td>\n",
       "      <td>314</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>JGXJ2801880132165</td>\n",
       "      <td>VJRK3495233458723</td>\n",
       "      <td>FWHP6221647324126</td>\n",
       "      <td>2018-05-10 07:50:26</td>\n",
       "      <td>16</td>\n",
       "      <td>229</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HDQU8860240235988</td>\n",
       "      <td>MFGZ4978234012602</td>\n",
       "      <td>AVPD5598148116569</td>\n",
       "      <td>2018-10-31 23:40:32</td>\n",
       "      <td>7</td>\n",
       "      <td>309</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id          client_id         account_id  \\\n",
       "0  BIGS2655386520335  SQWI6088247113041  UUJG9330648144708   \n",
       "1  BVVC7567878745629  EVEL6951619336672  PZWH9597088886612   \n",
       "2  UUSU6640167293035  MLFH5670327424978  JHZB9470931550704   \n",
       "3  JGXJ2801880132165  VJRK3495233458723  FWHP6221647324126   \n",
       "4  HDQU8860240235988  MFGZ4978234012602  AVPD5598148116569   \n",
       "\n",
       "                  date  duration_minutes  amount        type  \n",
       "0  2018-08-21 12:59:47                10     238  Withdrawal  \n",
       "1  2018-07-28 21:21:51                16     387  Withdrawal  \n",
       "2  2018-09-01 00:44:48                12     314  Withdrawal  \n",
       "3  2018-05-10 07:50:26                16     229  Withdrawal  \n",
       "4  2018-10-31 23:40:32                 7     309  Withdrawal  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['transactional_data'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_xucwOwq4gc"
   },
   "source": [
    "**Note**:\n",
    "* \n",
    "* *transaction_id* column seem to have no useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7hZGd7gq4gk"
   },
   "source": [
    "### 3 - **Checking Data types**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "co90787_q4gl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatypes for -personal- dataset are:\n",
      "\n",
      "is_married                bool\n",
      "age                      int64\n",
      "name                    object\n",
      "number_of_children       int64\n",
      "car_licence_plate       object\n",
      "address                 object\n",
      "has_criminal_records      bool\n",
      "smoker                    bool\n",
      "years_of_education       int64\n",
      "phone_number            object\n",
      "client_id               object\n",
      "email_domain            object\n",
      "dtype: object\n",
      "\n",
      "Datatypes for -job- dataset are:\n",
      "\n",
      "years_in_current_job     int64\n",
      "client_id               object\n",
      "salary                   int64\n",
      "phone_number            object\n",
      "car_licence_plate       object\n",
      "company                 object\n",
      "email_domain            object\n",
      "address                 object\n",
      "current_job             object\n",
      "dtype: object\n",
      "\n",
      "Datatypes for -bank_data- dataset are:\n",
      "\n",
      "number_secret_keys_requested           int64\n",
      "credit_card_provider                  object\n",
      "number_logs_per_day                    int64\n",
      "first_credit_card_application_date    object\n",
      "last_credit_card_application_date     object\n",
      "credit_score                           int64\n",
      "credit_card_number                     int64\n",
      "number_of_credit_cards                 int64\n",
      "account_id                            object\n",
      "credit_card_expire                    object\n",
      "client_id                             object\n",
      "defaulted_loan                          bool\n",
      "dtype: object\n",
      "\n",
      "Datatypes for -transactional_data- dataset are:\n",
      "\n",
      "transaction_id      object\n",
      "client_id           object\n",
      "account_id          object\n",
      "date                object\n",
      "duration_minutes     int64\n",
      "amount               int64\n",
      "type                object\n",
      "dtype: object\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(\"Datatypes for -\" + x + \"- dataset are:\\n\\n\" + f\"{data['train'][x].dtypes}\\n\", end = \"\\n\") for x in data['train'].keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbjQwDgdq4gn"
   },
   "source": [
    "### 4 - **Checking Null Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5moW9JYmq4go",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -personal- contains the following number of null values by feature: \n",
      "\n",
      "is_married              0\n",
      "age                     0\n",
      "name                    0\n",
      "number_of_children      0\n",
      "car_licence_plate       0\n",
      "address                 0\n",
      "has_criminal_records    0\n",
      "smoker                  0\n",
      "years_of_education      0\n",
      "phone_number            0\n",
      "client_id               0\n",
      "email_domain            0\n",
      "dtype: int64\n",
      "\n",
      "Dataset -job- contains the following number of null values by feature: \n",
      "\n",
      "years_in_current_job    0\n",
      "client_id               0\n",
      "salary                  0\n",
      "phone_number            0\n",
      "car_licence_plate       0\n",
      "company                 0\n",
      "email_domain            0\n",
      "address                 0\n",
      "current_job             0\n",
      "dtype: int64\n",
      "\n",
      "Dataset -bank_data- contains the following number of null values by feature: \n",
      "\n",
      "number_secret_keys_requested          0\n",
      "credit_card_provider                  0\n",
      "number_logs_per_day                   0\n",
      "first_credit_card_application_date    0\n",
      "last_credit_card_application_date     0\n",
      "credit_score                          0\n",
      "credit_card_number                    0\n",
      "number_of_credit_cards                0\n",
      "account_id                            0\n",
      "credit_card_expire                    0\n",
      "client_id                             0\n",
      "defaulted_loan                        0\n",
      "dtype: int64\n",
      "\n",
      "Dataset -transactional_data- contains the following number of null values by feature: \n",
      "\n",
      "transaction_id      0\n",
      "client_id           0\n",
      "account_id          0\n",
      "date                0\n",
      "duration_minutes    0\n",
      "amount              0\n",
      "type                0\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(\"Dataset -\" + x + \"- contains the following number of null values by feature: \\n\\n\" + f\"{data['train'][x].isnull().sum()}\\n\", end = \"\\n\") for x in data['train'].keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "glZ0vx1Qq4gq"
   },
   "source": [
    "**Note**:\n",
    "    * No missing values found in the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - **Checking number of repeated values in ID columns**\n",
    "\n",
    "This is done to define what kind of merging to do later on the datasets and expect certain behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "For dataset personal\n",
      "There are 68992 distinct client_id\n",
      "----------------------------------------------------------------------------------------------------\n",
      "For dataset job\n",
      "There are 68992 distinct client_id\n",
      "----------------------------------------------------------------------------------------------------\n",
      "For dataset bank_data\n",
      "There are 68992 distinct account_id\n",
      "There are 68992 distinct client_id\n",
      "----------------------------------------------------------------------------------------------------\n",
      "For dataset transactional_data\n",
      "There are 1517581 distinct transaction_id\n",
      "There are 68992 distinct client_id\n",
      "There are 68992 distinct account_id\n"
     ]
    }
   ],
   "source": [
    "for dataset in data[\"train\"]:\n",
    "    df = data[\"train\"][dataset]\n",
    "    print(\"-\"*100)\n",
    "    print(\"For dataset \" + dataset)\n",
    "    for id_col in df.columns:\n",
    "        if \"_id\" in id_col:\n",
    "            num_uniques = len(df[id_col].unique())\n",
    "            print(\"There are \"+ str(num_uniques) + \" distinct \" + id_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous outputs we can conclude that:\n",
    "- There are no repeated clients in the personal dataset.\n",
    "- One client has exactly one job in the job dataset.\n",
    "- One client has exactly one account in the bank data dataset.\n",
    "- One client has 1 or more transactions in the transactional dataset.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "In order to later use the dataset *transactional data* to make one single prediction per client, we have to group the data by client, engineering features from it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWkt3LRfq4gr"
   },
   "source": [
    "### 6 - **Label stats**\n",
    "- **defaulted_loan**: if True, it means that the client defaulted the loan. If False, client paid the loan.\n",
    "- **Our interest is to predict if a credit applicant (client_id) will default the loan.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4n5jjKYq4gs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    65527\n",
       "True      3465\n",
       "Name: defaulted_loan, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['bank_data']['defaulted_loan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0im7FRZAq4gx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    95.0\n",
       "True      5.0\n",
       "Name: defaulted_loan, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * np.round(data['train']['bank_data']['defaulted_loan'].value_counts() / data['train']['bank_data'].shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDYnYfQPq4gw"
   },
   "source": [
    "**Note**:\n",
    "- Currently, only 5% of the portfilio has defaulted the loan. This indicates that we will have to later manage an unbalanced label dataset to get better expected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGlc3Ch7q4g0"
   },
   "source": [
    "## Test set exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3j7AJjZq4g0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: personal | Dataset dimension (rows, cols): (29568, 12)\n",
      "Dataset: job | Dataset dimension (rows, cols): (29568, 9)\n",
      "Dataset: bank_data | Dataset dimension (rows, cols): (29568, 11)\n",
      "Dataset: transactional_data | Dataset dimension (rows, cols): (649132, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Dataset: ' + x + ' | Dataset dimension (rows, cols): ' + str(data['test'][x].shape)) for x in data['test'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62RMRYSEq4g2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -personal- contains the following number of null values by feature: \n",
      "\n",
      "is_married              0\n",
      "age                     0\n",
      "name                    0\n",
      "number_of_children      0\n",
      "car_licence_plate       0\n",
      "address                 0\n",
      "has_criminal_records    0\n",
      "smoker                  0\n",
      "years_of_education      0\n",
      "phone_number            0\n",
      "client_id               0\n",
      "email_domain            0\n",
      "dtype: int64\n",
      "\n",
      "Dataset -job- contains the following number of null values by feature: \n",
      "\n",
      "years_in_current_job    0\n",
      "client_id               0\n",
      "salary                  0\n",
      "phone_number            0\n",
      "car_licence_plate       0\n",
      "company                 0\n",
      "email_domain            0\n",
      "address                 0\n",
      "current_job             0\n",
      "dtype: int64\n",
      "\n",
      "Dataset -bank_data- contains the following number of null values by feature: \n",
      "\n",
      "number_secret_keys_requested          0\n",
      "credit_card_provider                  0\n",
      "number_logs_per_day                   0\n",
      "first_credit_card_application_date    0\n",
      "last_credit_card_application_date     0\n",
      "credit_score                          0\n",
      "credit_card_number                    0\n",
      "number_of_credit_cards                0\n",
      "account_id                            0\n",
      "credit_card_expire                    0\n",
      "client_id                             0\n",
      "dtype: int64\n",
      "\n",
      "Dataset -transactional_data- contains the following number of null values by feature: \n",
      "\n",
      "transaction_id      0\n",
      "client_id           0\n",
      "account_id          0\n",
      "date                0\n",
      "duration_minutes    0\n",
      "amount              0\n",
      "type                0\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(\"Dataset -\" + x + \"- contains the following number of null values by feature: \\n\\n\" + f\"{data['test'][x].isnull().sum()}\\n\", end = \"\\n\") for x in data['test'].keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "voLwi5mDq4g5"
   },
   "source": [
    "**Note**:\n",
    "- No missing values found in the train set.\n",
    "\n",
    "For simplicity, we will assume:\n",
    "* Test set comes from the same distribution as train set (therefore the same distribution of dev set).\n",
    "* Test set does not contain values not contained in the train set for categorical one-hot encoded features (as this would require to handle this exceptions by replacing those values, droping rows with those values or redefining the feature encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nw94afyJq4g5"
   },
   "source": [
    "# Data wrangling and feature extraction for Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8lEF1PBq4g6"
   },
   "source": [
    "The goal of this section is to preprocess data to make EDA reveal clearer patterns more easily.\n",
    "\n",
    "In this section we preprocess train and test data the same way to later be able to use the same model to make predictions on both.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "Feature extraction is only one of a series of iterative trial and error steps in the machine learning cycle. This is only a first approach.\n",
    "\n",
    "## Dropping not useful columns from datasets\n",
    "\n",
    "As mentioned on the Train Data Exploration section, we may remove the following unuseful feature columns from datasets:\n",
    "* name\n",
    "* address\n",
    "* car_licence_plate\n",
    "* phone_number\n",
    "* email_domain \n",
    "* credit_card_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QG5Os8OGq4g8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* personal training dataset  columns:\n",
      "* job training dataset  columns:\n",
      "* bank_data training dataset  columns:\n",
      "* transactional_data training dataset  columns:\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"car_licence_plate\", \"phone_number\", \"email_domain\", \"name\", \"address\", \n",
    "                   \"credit_card_number\", \"credit_card_number\"]\n",
    "\n",
    "for dataset in data[\"train\"]:\n",
    "    data[\"train\"][dataset] = \\\n",
    "    data[\"train\"][dataset].drop([columname for columname in data[\"train\"][dataset].columns\n",
    "                                 if columname in columns_to_drop], axis = 1)\n",
    "    print(\"* \" + dataset + \" training dataset \" + \" columns:\")\n",
    "#     print(data[\"train\"][dataset].columns.values, end = \"\\n\\n\") # Uncomment this line to validate if the operation is succesful\n",
    "\n",
    "for dataset in data[\"test\"]:\n",
    "    data[\"test\"][dataset] = \\\n",
    "    data[\"test\"][dataset].drop([columname for columname in data[\"test\"][dataset].columns \n",
    "                                 if columname in columns_to_drop], axis = 1)\n",
    "#     print(data[\"test\"][dataset].columns) # Uncomment this line to validate if the operation is succesful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8lEF1PBq4g6"
   },
   "source": [
    "## Converting date columns to datetime type\n",
    "\n",
    "The following columns currently are of type \"object\", they should be of type \"datetime\":\n",
    "* credit_card_expire (from bank_data dataset)\n",
    "* first_credit_card_application_date (from bank_data dataset)\n",
    "* last_credit_card_application_date (from bank_data dataset)\n",
    "* date (from transactional_data dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"train\", \"test\"]:\n",
    "    data[dataset][\"bank_data\"].credit_card_expire = data[dataset][\"bank_data\"].credit_card_expire.apply(lambda x: pd.to_datetime(r\"01/\" +x ))\n",
    "    data[dataset][\"bank_data\"].first_credit_card_application_date = data[dataset][\"bank_data\"].first_credit_card_application_date.apply(pd.to_datetime, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    data[dataset][\"bank_data\"].last_credit_card_application_date = data[dataset][\"bank_data\"].last_credit_card_application_date.apply(pd.to_datetime, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    data[dataset][\"transactional_data\"].date = data[dataset][\"transactional_data\"].date.apply(pd.to_datetime, format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing data successful type transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_card_expire                    datetime64[ns]\n",
       "first_credit_card_application_date    datetime64[ns]\n",
       "last_credit_card_application_date     datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"bank_data\"][[\"credit_card_expire\", \"first_credit_card_application_date\", \n",
    "                            \"last_credit_card_application_date\"]].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"transactional_data\"][[\"date\"]].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOVERzccwDTd"
   },
   "source": [
    "## Generating *transactional_data* dataset grouped by _client_id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qw83WuWtwDnS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transactional_data_gr dataset contains the following columns generated by grouping by client_id: \n",
      " \n",
      "['client_id' 'withdrawal_num_transactions_count' 'withdrawal_amount_mean'\n",
      " 'withdrawal_amount_sum' 'withdrawal_duration_minutes_mean'\n",
      " 'withdrawal_date_min' 'withdrawal_date_max'\n",
      " 'deposit_num_transactions_count' 'deposit_amount_mean'\n",
      " 'deposit_amount_sum' 'deposit_duration_minutes_mean' 'deposit_date_min'\n",
      " 'deposit_date_max']\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"train\", \"test\"]:\n",
    "    df = data[dataset][\"transactional_data\"]\n",
    "    # Defining new dataset with a single column of unique client IDs\n",
    "    data[dataset][\"transactional_data_gr\"] = pd.DataFrame(pd.Series(df.client_id.unique()), columns = [\"client_id\"])\n",
    "    # Filtering transactional_data dataset for each transaction type to calculate aggregation metrics on it\n",
    "    for transaction_type in df.type.unique():\n",
    "        temp = df[df.type == transaction_type]\n",
    "        # Calculating aggregation metrics\n",
    "        temp = temp.groupby([\"client_id\"]).agg({\"client_id\": \"count\", \"amount\": [\"mean\", \"sum\"], \"duration_minutes\": \"mean\", \"date\": [\"min\", \"max\"]})\n",
    "        temp = temp.rename(columns = {\"client_id\": \"num_transactions\"})\n",
    "        temp.columns = [(transaction_type.lower() + \"_\" + col[0] + \"_\" + col[1]) for col in temp.columns] # Renaming columns by transaction type\n",
    "        temp = temp.reset_index()\n",
    "        data[dataset][\"transactional_data_gr\"] = data[dataset][\"transactional_data_gr\"].merge(temp, on = \"client_id\")\n",
    "    # Making sure all client_id rows are unique\n",
    "    assert len(data[dataset][\"transactional_data_gr\"]) == len(data[dataset][\"transactional_data_gr\"].client_id.unique())\n",
    "\n",
    "print(\"The transactional_data_gr dataset contains the following columns generated by grouping by client_id: \\n \")\n",
    "print(data[dataset][\"transactional_data_gr\"].columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature-engineered columns generated so far are for each transaction type:\n",
    "* number of transactions\n",
    "* mean and total sum of amounts\n",
    "* mean duration (in minutes)\n",
    "* max and min transaction dates\n",
    "\n",
    "Showing the resulting grouped dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>withdrawal_num_transactions_count</th>\n",
       "      <th>withdrawal_amount_mean</th>\n",
       "      <th>withdrawal_amount_sum</th>\n",
       "      <th>withdrawal_duration_minutes_mean</th>\n",
       "      <th>withdrawal_date_min</th>\n",
       "      <th>withdrawal_date_max</th>\n",
       "      <th>deposit_num_transactions_count</th>\n",
       "      <th>deposit_amount_mean</th>\n",
       "      <th>deposit_amount_sum</th>\n",
       "      <th>deposit_duration_minutes_mean</th>\n",
       "      <th>deposit_date_min</th>\n",
       "      <th>deposit_date_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SQWI6088247113041</td>\n",
       "      <td>16</td>\n",
       "      <td>272.812500</td>\n",
       "      <td>4365</td>\n",
       "      <td>11.812500</td>\n",
       "      <td>2018-02-07 02:55:08</td>\n",
       "      <td>2018-12-26 04:26:36</td>\n",
       "      <td>11</td>\n",
       "      <td>304.363636</td>\n",
       "      <td>3348</td>\n",
       "      <td>12.454545</td>\n",
       "      <td>2018-01-14 10:38:35</td>\n",
       "      <td>2018-10-17 13:25:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>EVEL6951619336672</td>\n",
       "      <td>20</td>\n",
       "      <td>323.300000</td>\n",
       "      <td>6466</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>2018-02-20 03:57:58</td>\n",
       "      <td>2018-12-17 05:28:46</td>\n",
       "      <td>11</td>\n",
       "      <td>279.636364</td>\n",
       "      <td>3076</td>\n",
       "      <td>13.545455</td>\n",
       "      <td>2018-01-15 19:35:45</td>\n",
       "      <td>2018-12-19 13:54:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MLFH5670327424978</td>\n",
       "      <td>15</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>4830</td>\n",
       "      <td>12.133333</td>\n",
       "      <td>2018-01-25 18:07:55</td>\n",
       "      <td>2018-12-29 23:21:53</td>\n",
       "      <td>8</td>\n",
       "      <td>298.625000</td>\n",
       "      <td>2389</td>\n",
       "      <td>10.875000</td>\n",
       "      <td>2018-02-11 02:15:42</td>\n",
       "      <td>2019-01-04 11:27:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>VJRK3495233458723</td>\n",
       "      <td>27</td>\n",
       "      <td>321.518519</td>\n",
       "      <td>8681</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2018-01-09 00:09:17</td>\n",
       "      <td>2018-12-31 23:13:15</td>\n",
       "      <td>12</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>3420</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>2018-01-09 16:54:29</td>\n",
       "      <td>2018-12-24 16:15:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MFGZ4978234012602</td>\n",
       "      <td>25</td>\n",
       "      <td>310.840000</td>\n",
       "      <td>7771</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>2018-01-26 17:26:30</td>\n",
       "      <td>2019-01-04 05:08:41</td>\n",
       "      <td>14</td>\n",
       "      <td>297.071429</td>\n",
       "      <td>4159</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>2018-01-08 08:54:44</td>\n",
       "      <td>2018-11-13 16:28:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           client_id  withdrawal_num_transactions_count  \\\n",
       "0  SQWI6088247113041                                 16   \n",
       "1  EVEL6951619336672                                 20   \n",
       "2  MLFH5670327424978                                 15   \n",
       "3  VJRK3495233458723                                 27   \n",
       "4  MFGZ4978234012602                                 25   \n",
       "\n",
       "   withdrawal_amount_mean  withdrawal_amount_sum  \\\n",
       "0              272.812500                   4365   \n",
       "1              323.300000                   6466   \n",
       "2              322.000000                   4830   \n",
       "3              321.518519                   8681   \n",
       "4              310.840000                   7771   \n",
       "\n",
       "   withdrawal_duration_minutes_mean withdrawal_date_min withdrawal_date_max  \\\n",
       "0                         11.812500 2018-02-07 02:55:08 2018-12-26 04:26:36   \n",
       "1                         12.300000 2018-02-20 03:57:58 2018-12-17 05:28:46   \n",
       "2                         12.133333 2018-01-25 18:07:55 2018-12-29 23:21:53   \n",
       "3                         12.000000 2018-01-09 00:09:17 2018-12-31 23:13:15   \n",
       "4                         11.800000 2018-01-26 17:26:30 2019-01-04 05:08:41   \n",
       "\n",
       "   deposit_num_transactions_count  deposit_amount_mean  deposit_amount_sum  \\\n",
       "0                              11           304.363636                3348   \n",
       "1                              11           279.636364                3076   \n",
       "2                               8           298.625000                2389   \n",
       "3                              12           285.000000                3420   \n",
       "4                              14           297.071429                4159   \n",
       "\n",
       "   deposit_duration_minutes_mean    deposit_date_min    deposit_date_max  \n",
       "0                      12.454545 2018-01-14 10:38:35 2018-10-17 13:25:52  \n",
       "1                      13.545455 2018-01-15 19:35:45 2018-12-19 13:54:34  \n",
       "2                      10.875000 2018-02-11 02:15:42 2019-01-04 11:27:07  \n",
       "3                      10.333333 2018-01-09 16:54:29 2018-12-24 16:15:12  \n",
       "4                      13.142857 2018-01-08 08:54:44 2018-11-13 16:28:25  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"transactional_data_gr\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id                                    object\n",
       "withdrawal_num_transactions_count             int64\n",
       "withdrawal_amount_mean                      float64\n",
       "withdrawal_amount_sum                         int64\n",
       "withdrawal_duration_minutes_mean            float64\n",
       "withdrawal_date_min                  datetime64[ns]\n",
       "withdrawal_date_max                  datetime64[ns]\n",
       "deposit_num_transactions_count                int64\n",
       "deposit_amount_mean                         float64\n",
       "deposit_amount_sum                            int64\n",
       "deposit_duration_minutes_mean               float64\n",
       "deposit_date_min                     datetime64[ns]\n",
       "deposit_date_max                     datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"transactional_data_gr\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZV3KTYGq4hB"
   },
   "source": [
    "## Merging datasets into single train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQldYRK-q4hC",
    "outputId": "8cdb764e-0d9f-44bf-a01e-bc3899f357ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final 32 trainset columns are: \n",
      "\n",
      " Index(['is_married', 'age', 'number_of_children', 'has_criminal_records',\n",
      "       'smoker', 'years_of_education', 'client_id', 'years_in_current_job',\n",
      "       'salary', 'company', 'current_job', 'number_secret_keys_requested',\n",
      "       'credit_card_provider', 'number_logs_per_day',\n",
      "       'first_credit_card_application_date',\n",
      "       'last_credit_card_application_date', 'credit_score',\n",
      "       'number_of_credit_cards', 'credit_card_expire', 'defaulted_loan',\n",
      "       'withdrawal_num_transactions_count', 'withdrawal_amount_mean',\n",
      "       'withdrawal_amount_sum', 'withdrawal_duration_minutes_mean',\n",
      "       'withdrawal_date_min', 'withdrawal_date_max',\n",
      "       'deposit_num_transactions_count', 'deposit_amount_mean',\n",
      "       'deposit_amount_sum', 'deposit_duration_minutes_mean',\n",
      "       'deposit_date_min', 'deposit_date_max'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for d_set in [\"train\", \"test\"]:    \n",
    "    data[d_set][\"merged_\"+d_set] = data[d_set]['personal'].merge(data[\"train\"]['job'], on = \"client_id\", how = \"left\")\n",
    "    data[d_set][\"merged_\"+d_set] = data[d_set][\"merged_\"+d_set].merge(data[d_set]['bank_data'], on = \"client_id\", how = \"left\")\n",
    "    data[d_set][\"merged_\"+d_set] = data[d_set][\"merged_\"+d_set].merge(data[d_set]['transactional_data_gr'], on = \"client_id\", how = \"left\")\n",
    "    # Droping id columns except client_id\n",
    "    data[d_set][\"merged_\"+d_set] = data[d_set][\"merged_\"+d_set].drop([\"account_id\"], axis = 1)\n",
    "\n",
    "print(\"The final \" + str(len(data[\"train\"][\"merged_train\"].columns)) + \" trainset columns are: \\n\\n \" + \\\n",
    "  str(data[\"train\"][\"merged_train\"].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_married</th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_children</th>\n",
       "      <th>has_criminal_records</th>\n",
       "      <th>smoker</th>\n",
       "      <th>years_of_education</th>\n",
       "      <th>client_id</th>\n",
       "      <th>years_in_current_job</th>\n",
       "      <th>salary</th>\n",
       "      <th>company</th>\n",
       "      <th>...</th>\n",
       "      <th>withdrawal_amount_sum</th>\n",
       "      <th>withdrawal_duration_minutes_mean</th>\n",
       "      <th>withdrawal_date_min</th>\n",
       "      <th>withdrawal_date_max</th>\n",
       "      <th>deposit_num_transactions_count</th>\n",
       "      <th>deposit_amount_mean</th>\n",
       "      <th>deposit_amount_sum</th>\n",
       "      <th>deposit_duration_minutes_mean</th>\n",
       "      <th>deposit_date_min</th>\n",
       "      <th>deposit_date_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>MUMR3875397452595</td>\n",
       "      <td>10</td>\n",
       "      <td>9383</td>\n",
       "      <td>Williams, Bailey and Smith</td>\n",
       "      <td>...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>2018-02-06 07:26:03</td>\n",
       "      <td>2018-12-20 11:54:47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>369.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2018-08-05 15:35:14</td>\n",
       "      <td>2018-08-05 15:35:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>LNFC4821269126830</td>\n",
       "      <td>8</td>\n",
       "      <td>5205</td>\n",
       "      <td>Kim, Salas and Snyder</td>\n",
       "      <td>...</td>\n",
       "      <td>9341.0</td>\n",
       "      <td>11.655172</td>\n",
       "      <td>2018-01-30 22:33:51</td>\n",
       "      <td>2018-12-19 12:56:47</td>\n",
       "      <td>12.0</td>\n",
       "      <td>324.166667</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>11.583333</td>\n",
       "      <td>2018-02-15 20:13:32</td>\n",
       "      <td>2018-12-24 22:08:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>PIGP5747447418648</td>\n",
       "      <td>15</td>\n",
       "      <td>10431</td>\n",
       "      <td>Coleman LLC</td>\n",
       "      <td>...</td>\n",
       "      <td>5781.0</td>\n",
       "      <td>13.555556</td>\n",
       "      <td>2018-04-08 10:49:24</td>\n",
       "      <td>2018-12-31 09:00:30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.428571</td>\n",
       "      <td>2082.0</td>\n",
       "      <td>13.857143</td>\n",
       "      <td>2018-03-05 06:57:03</td>\n",
       "      <td>2018-12-07 07:20:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>MDZY2927886938414</td>\n",
       "      <td>9</td>\n",
       "      <td>8779</td>\n",
       "      <td>Hogan, Trujillo and Hall</td>\n",
       "      <td>...</td>\n",
       "      <td>5393.0</td>\n",
       "      <td>12.529412</td>\n",
       "      <td>2018-01-24 17:03:46</td>\n",
       "      <td>2019-01-03 16:36:42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>392.500000</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>2018-01-26 20:52:54</td>\n",
       "      <td>2018-11-26 08:12:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>WETM2827630477279</td>\n",
       "      <td>14</td>\n",
       "      <td>5747</td>\n",
       "      <td>Clay Inc</td>\n",
       "      <td>...</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>11.727273</td>\n",
       "      <td>2018-01-30 06:56:41</td>\n",
       "      <td>2018-12-25 12:46:04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>301.833333</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>2018-03-17 14:15:40</td>\n",
       "      <td>2018-12-08 06:15:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_married  age  number_of_children  has_criminal_records  smoker  \\\n",
       "0       False   31                   2                 False    True   \n",
       "1       False   26                   3                  True    True   \n",
       "2        True   29                   3                 False    True   \n",
       "3        True   34                   1                 False   False   \n",
       "4        True   33                   3                 False    True   \n",
       "\n",
       "   years_of_education          client_id  years_in_current_job  salary  \\\n",
       "0                  14  MUMR3875397452595                    10    9383   \n",
       "1                  17  LNFC4821269126830                     8    5205   \n",
       "2                  17  PIGP5747447418648                    15   10431   \n",
       "3                   8  MDZY2927886938414                     9    8779   \n",
       "4                  13  WETM2827630477279                    14    5747   \n",
       "\n",
       "                      company  ... withdrawal_amount_sum  \\\n",
       "0  Williams, Bailey and Smith  ...                1981.0   \n",
       "1       Kim, Salas and Snyder  ...                9341.0   \n",
       "2                 Coleman LLC  ...                5781.0   \n",
       "3    Hogan, Trujillo and Hall  ...                5393.0   \n",
       "4                    Clay Inc  ...                3371.0   \n",
       "\n",
       "   withdrawal_duration_minutes_mean withdrawal_date_min  withdrawal_date_max  \\\n",
       "0                         13.666667 2018-02-06 07:26:03  2018-12-20 11:54:47   \n",
       "1                         11.655172 2018-01-30 22:33:51  2018-12-19 12:56:47   \n",
       "2                         13.555556 2018-04-08 10:49:24  2018-12-31 09:00:30   \n",
       "3                         12.529412 2018-01-24 17:03:46  2019-01-03 16:36:42   \n",
       "4                         11.727273 2018-01-30 06:56:41  2018-12-25 12:46:04   \n",
       "\n",
       "  deposit_num_transactions_count deposit_amount_mean  deposit_amount_sum  \\\n",
       "0                            1.0          369.000000               369.0   \n",
       "1                           12.0          324.166667              3890.0   \n",
       "2                            7.0          297.428571              2082.0   \n",
       "3                            6.0          392.500000              2355.0   \n",
       "4                            6.0          301.833333              1811.0   \n",
       "\n",
       "   deposit_duration_minutes_mean    deposit_date_min    deposit_date_max  \n",
       "0                      11.000000 2018-08-05 15:35:14 2018-08-05 15:35:14  \n",
       "1                      11.583333 2018-02-15 20:13:32 2018-12-24 22:08:13  \n",
       "2                      13.857143 2018-03-05 06:57:03 2018-12-07 07:20:14  \n",
       "3                      13.500000 2018-01-26 20:52:54 2018-11-26 08:12:05  \n",
       "4                      12.666667 2018-03-17 14:15:40 2018-12-08 06:15:37  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"merged_train\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further feature engineering\n",
    "\n",
    "We may perform further feature engineering by defining the next columns:\n",
    "\n",
    "* transaction_days_range : Range of days between first and last transaction (float32).\n",
    "* first_transaction_month : Month of first transaction (str).\n",
    "* first_transaction_year : Year of first transaction (str).\n",
    "* monthly_avg_withdrawals : Monthly average withdrawal number (float32).\n",
    "* monthly_avg_deposits : Monthly average deposit number (float32).\n",
    "* monthly_avg_w_amount : Monthly average withdrawal amount (float32).\n",
    "* monthly_avg_d_amount : Monthly average deposit amount (float32).\n",
    "* first_cc_app_month : Month of first credit card application date (str).\n",
    "* first_cc_app_year : Year of first credit card application date (str).\n",
    "* cc_expire_month : Month of credit card expire date (str).\n",
    "* cc_expire_year : Year of credit card expire date (str)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    df[\"first_transaction\"] = df.apply(lambda x: max(x.withdrawal_date_min, x.deposit_date_min), axis = 1)\n",
    "    df[\"last_transaction\"] = df.apply(lambda x: min(x.withdrawal_date_max, x.deposit_date_max), axis = 1)\n",
    "    df[\"transaction_days_range\"] = df.apply(lambda x: (x.last_transaction - x.first_transaction).days, axis = 1)\n",
    "    df[\"first_transaction_month\"] = df.apply(lambda x: min(x.withdrawal_date_min, x.deposit_date_min).month, axis = 1)\n",
    "    df[\"first_transaction_year\"] = df.apply(lambda x: min(x.withdrawal_date_min, x.deposit_date_min).year, axis = 1)\n",
    "    df[\"monthly_avg_withdrawals\"] = df.withdrawal_num_transactions_count/(df.transaction_days_range.apply(lambda x: x/30))\n",
    "    df[\"monthly_avg_deposits\"] = df.deposit_num_transactions_count/(df.transaction_days_range.apply(lambda x: x/30))\n",
    "    df[\"monthly_avg_w_amount\"] = df.withdrawal_amount_sum/(df.transaction_days_range.apply(lambda x: x/30))\n",
    "    df[\"monthly_avg_d_amount\"] = df.deposit_amount_sum/(df.transaction_days_range.apply(lambda x: x/30))\n",
    "    df[\"first_cc_app_month\"] =  df.first_credit_card_application_date.apply(lambda x: x.month)\n",
    "    df[\"first_cc_app_year\"] :df.first_credit_card_application_date.apply(lambda x: x.year)\n",
    "    df[\"cc_expire_month\"] = df.credit_card_expire.apply(lambda x: x.month)\n",
    "    df[\"cc_expire_year\"] = df.credit_card_expire.apply(lambda x: x.year)\n",
    "    return df\n",
    "\n",
    "for d_set in [\"train\", \"test\"]:    \n",
    "    data[d_set][\"merged_\"+d_set] = feat_eng(data[d_set][\"merged_\"+d_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And droping the following (not useful anymore) columns:\n",
    "\n",
    "* first_transaction\n",
    "* last_transaction\n",
    "* withdrawal_date_min\n",
    "* withdrawal_date_max\n",
    "* deposit_date_min\n",
    "* deposit_date_max\n",
    "* first_credit_card_application_date\n",
    "* last_credit_card_application_date\n",
    "* creditcard_expire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"first_transaction\",\n",
    "                   \"last_transaction\", \n",
    "                   \"withdrawal_date_min\", \n",
    "                    \"withdrawal_date_max\",\n",
    "                    \"deposit_date_min\",\n",
    "                    \"first_credit_card_application_date\",\n",
    "                    \"last_credit_card_application_date\",\n",
    "                    \"deposit_date_min\", \n",
    "                    \"deposit_date_max\", \n",
    "                    \"credit_card_expire\"]\n",
    "\n",
    "\n",
    "data[\"train\"][\"merged_train\"] = data[\"train\"][\"merged_train\"].drop(columns_to_drop, axis = 1)\n",
    "data[\"test\"][\"merged_test\"] = data[\"test\"][\"merged_test\"].drop(columns_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the following resulting merged dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_married</th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_children</th>\n",
       "      <th>has_criminal_records</th>\n",
       "      <th>smoker</th>\n",
       "      <th>years_of_education</th>\n",
       "      <th>client_id</th>\n",
       "      <th>years_in_current_job</th>\n",
       "      <th>salary</th>\n",
       "      <th>company</th>\n",
       "      <th>...</th>\n",
       "      <th>transaction_days_range</th>\n",
       "      <th>first_transaction_month</th>\n",
       "      <th>first_transaction_year</th>\n",
       "      <th>monthly_avg_withdrawals</th>\n",
       "      <th>monthly_avg_deposits</th>\n",
       "      <th>monthly_avg_w_amount</th>\n",
       "      <th>monthly_avg_d_amount</th>\n",
       "      <th>first_cc_app_month</th>\n",
       "      <th>cc_expire_month</th>\n",
       "      <th>cc_expire_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>MUMR3875397452595</td>\n",
       "      <td>10</td>\n",
       "      <td>9383</td>\n",
       "      <td>Williams, Bailey and Smith</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>LNFC4821269126830</td>\n",
       "      <td>8</td>\n",
       "      <td>5205</td>\n",
       "      <td>Kim, Salas and Snyder</td>\n",
       "      <td>...</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.843137</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>915.784314</td>\n",
       "      <td>381.372549</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>PIGP5747447418648</td>\n",
       "      <td>15</td>\n",
       "      <td>10431</td>\n",
       "      <td>Coleman LLC</td>\n",
       "      <td>...</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.231405</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>716.652893</td>\n",
       "      <td>258.099174</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>MDZY2927886938414</td>\n",
       "      <td>9</td>\n",
       "      <td>8779</td>\n",
       "      <td>Hogan, Trujillo and Hall</td>\n",
       "      <td>...</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.683168</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>533.960396</td>\n",
       "      <td>233.168317</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>WETM2827630477279</td>\n",
       "      <td>14</td>\n",
       "      <td>5747</td>\n",
       "      <td>Clay Inc</td>\n",
       "      <td>...</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.245283</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>381.622642</td>\n",
       "      <td>205.018868</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_married  age  number_of_children  has_criminal_records  smoker  \\\n",
       "0       False   31                   2                 False    True   \n",
       "1       False   26                   3                  True    True   \n",
       "2        True   29                   3                 False    True   \n",
       "3        True   34                   1                 False   False   \n",
       "4        True   33                   3                 False    True   \n",
       "\n",
       "   years_of_education          client_id  years_in_current_job  salary  \\\n",
       "0                  14  MUMR3875397452595                    10    9383   \n",
       "1                  17  LNFC4821269126830                     8    5205   \n",
       "2                  17  PIGP5747447418648                    15   10431   \n",
       "3                   8  MDZY2927886938414                     9    8779   \n",
       "4                  13  WETM2827630477279                    14    5747   \n",
       "\n",
       "                      company  ... transaction_days_range  \\\n",
       "0  Williams, Bailey and Smith  ...                    0.0   \n",
       "1       Kim, Salas and Snyder  ...                  306.0   \n",
       "2                 Coleman LLC  ...                  242.0   \n",
       "3    Hogan, Trujillo and Hall  ...                  303.0   \n",
       "4                    Clay Inc  ...                  265.0   \n",
       "\n",
       "   first_transaction_month first_transaction_year  monthly_avg_withdrawals  \\\n",
       "0                      2.0                 2018.0                      inf   \n",
       "1                      1.0                 2018.0                 2.843137   \n",
       "2                      3.0                 2018.0                 2.231405   \n",
       "3                      1.0                 2018.0                 1.683168   \n",
       "4                      1.0                 2018.0                 1.245283   \n",
       "\n",
       "   monthly_avg_deposits  monthly_avg_w_amount  monthly_avg_d_amount  \\\n",
       "0                   inf                   inf                   inf   \n",
       "1              1.176471            915.784314            381.372549   \n",
       "2              0.867769            716.652893            258.099174   \n",
       "3              0.594059            533.960396            233.168317   \n",
       "4              0.679245            381.622642            205.018868   \n",
       "\n",
       "   first_cc_app_month  cc_expire_month  cc_expire_year  \n",
       "0                   4                1            2023  \n",
       "1                  11                1            2026  \n",
       "2                   6                1            2020  \n",
       "3                   9                1            2029  \n",
       "4                   8                1            2028  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"merged_train\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With column types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_married                                     bool\n",
       "age                                           int64\n",
       "number_of_children                            int64\n",
       "has_criminal_records                           bool\n",
       "smoker                                         bool\n",
       "years_of_education                            int64\n",
       "client_id                                    object\n",
       "years_in_current_job                          int64\n",
       "salary                                        int64\n",
       "company                                      object\n",
       "current_job                                  object\n",
       "number_secret_keys_requested                  int64\n",
       "credit_card_provider                         object\n",
       "number_logs_per_day                           int64\n",
       "credit_score                                  int64\n",
       "number_of_credit_cards                        int64\n",
       "defaulted_loan                                 bool\n",
       "withdrawal_num_transactions_count           float64\n",
       "withdrawal_amount_mean                      float64\n",
       "withdrawal_amount_sum                       float64\n",
       "withdrawal_duration_minutes_mean            float64\n",
       "deposit_num_transactions_count              float64\n",
       "deposit_amount_mean                         float64\n",
       "deposit_amount_sum                          float64\n",
       "deposit_duration_minutes_mean               float64\n",
       "first_transaction                    datetime64[ns]\n",
       "last_transaction                     datetime64[ns]\n",
       "transaction_days_range                      float64\n",
       "first_transaction_month                     float64\n",
       "first_transaction_year                      float64\n",
       "monthly_avg_withdrawals                     float64\n",
       "monthly_avg_deposits                        float64\n",
       "monthly_avg_w_amount                        float64\n",
       "monthly_avg_d_amount                        float64\n",
       "first_cc_app_month                            int64\n",
       "cc_expire_month                               int64\n",
       "cc_expire_year                                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"merged_train\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "## Dividing features by data type\n",
    "\n",
    "To generate better graphs, lets divide features into data into categorical, boolean and numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = data[\"train\"][\"merged_train\"].reset_index(drop = True)\n",
    "cat_cols = []\n",
    "bool_cols = []\n",
    "num_cols = []\n",
    "\n",
    "for column in eda_df.columns[eda_df.columns != \"client_id\"]:\n",
    "    if data[\"train\"][\"merged_train\"][column].dtypes in [\"object\"]:\n",
    "        cat_cols.append(column)\n",
    "    elif data[\"train\"][\"merged_train\"][column].dtypes in [\"bool\"]:\n",
    "        bool_cols.append(column)\n",
    "    else:\n",
    "        num_cols.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of unique values for categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company\n",
      "49178\n",
      "current_job\n",
      "639\n",
      "credit_card_provider\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    print(len(eda_df[col].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring company column\n",
    "\n",
    "Company column seems to not be a candidate for one-hot encoding without preprocessing, as it would generate 49178 columns.\n",
    "\n",
    "We can analyze the number of times a company appears in our training dataset to try grouping more relevant values (values for wich we may identify a clear pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>rows_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40552</td>\n",
       "      <td>Smith PLC</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40548</td>\n",
       "      <td>Smith Group</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40550</td>\n",
       "      <td>Smith LLC</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40551</td>\n",
       "      <td>Smith Ltd</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21454</td>\n",
       "      <td>Johnson PLC</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company  rows_count\n",
       "40552    Smith PLC          97\n",
       "40548  Smith Group          93\n",
       "40550    Smith LLC          92\n",
       "40551    Smith Ltd          77\n",
       "21454  Johnson PLC          76"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df = eda_df.groupby(\"company\", as_index = False).agg({\"client_id\": \"count\"})[[\"company\", \"client_id\"]].rename(columns = {\"client_id\": \"rows_count\"})\n",
    "company_df.sort_values(\"rows_count\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>49178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.402904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.349346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rows_count\n",
       "count  49178.000000\n",
       "mean       1.402904\n",
       "std        2.349346\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max       97.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that at least 75% of the 49178 listed companies have a single row (client_id) in our dataset, and the company with most rows is Smith PLC (97 rows).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_x_employees = company_df[\"rows_count\"].value_counts()\n",
    "companies_x_employees = companies_x_employees.reset_index().rename(columns = {\"index\": \"num_employees\", \"rows_count\": \"num_companies\"})\n",
    "more_20_emp_companies = companies_x_employees[companies_x_employees.num_employees > 20]\n",
    "print(\"By grouping all companies with 20 or more employees we are now left with: \" + str(len(more_20_emp_companies)) + \" companies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the values from the company column of the companies with less than 20 employees with the string \"Not Relevant\" and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "companies_to_replace = company_df[company_df.rows_count <= 20].company.unique()\n",
    "eda_df[eda_df.company.isin(companies_to_replace)] = \"Not Relevant\"\n",
    "# sns.countplot(x = \"company\", data = eda_df)\n",
    "len(eda_df.company.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring current_job column\n",
    "\n",
    "Company column seems to not be a candidate for one-hot encoding without preprocessing, as it would generate 639 columns.\n",
    "\n",
    "We can analyze the number of times a job appears in our training dataset to group the more relevant values (values for wich we may identify a clear pattern)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting scatterplots between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6puFd7baq4hE",
    "outputId": "089cb822-d548-4a3b-e69d-d13e3fbfc0ba",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data[\"train\"][\"personal\"].merge(data[\"train\"][\"bank_data\"][[\"client_id\", \"defaulted_loan\"]], \n",
    "                                             on = \"client_id\", how = \"left\"), hue=\"defaulted_loan\", diag_kind=\"kde\", s = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data[\"train\"][\"job\"].merge(data[\"train\"][\"bank_data\"][[\"client_id\", \"defaulted_loan\"]], \n",
    "                                             on = \"client_id\", how = \"left\"), hue=\"defaulted_loan\", diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYmFFDRgw8Hl"
   },
   "source": [
    "## Plotting pearson correlation matrix between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tcskf_pMxrJN"
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr = data[\"train\"][\"merged_train\"].corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        linewidths=.5,\n",
    "       cmap=\"RdBu_r\", center = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nw94afyJq4g5"
   },
   "source": [
    "# Feature extraction after Exploratory Data Analysis (EDA)\n",
    "\n",
    "A well designed EDA may lead us to the creation of relevant features.\n",
    "\n",
    "The goal of this section is to example the implementation of two features derived from EDA:\n",
    "* salary_per_children\n",
    "* salary_per_education_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"train\"][\"merged_train\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOTfu61hq4hG"
   },
   "source": [
    "# Building and comparing models performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data wrangling pipeline steps\n",
    "\n",
    "### 1) Null values Imputing\n",
    "\n",
    "Theo need to do imputing as the trainset and testset do not contain missing values \n",
    "\n",
    "### 2) Encoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#Separating categorical columns and numeric columns\n",
    "bool_columns = []\n",
    "categoric_columns = []\n",
    "numeric_columns = []\n",
    "date_columns = []\n",
    "for x in data[\"train\"][\"merged_train\"].columns:\n",
    "    if data[\"train\"][\"merged_train\"][x].dtypes in [\"object\"]:\n",
    "        categoric_columns.append(x)\n",
    "    elif data[\"train\"][\"merged_train\"][x].dtypes in [\"bool\"]:\n",
    "        bool_columns.append(x)\n",
    "    elif data[\"train\"][\"merged_train\"][x].dtypes in [\"int64\", \"float64\"]:\n",
    "        numeric_columns.append(x)\n",
    "    else:\n",
    "        date_columns.append(x)\n",
    "#Preprocessing date columns\n",
    "for col in date_columns:\n",
    "    data[\"train\"][\"merged_train\"][col+\"_year\"] = data[\"train\"][\"merged_train\"][col].dt.year\n",
    "    data[\"train\"][\"merged_train\"][col+\"_month\"] = data[\"train\"][\"merged_train\"][col].dt.month\n",
    "    data[\"train\"][\"merged_train\"][col+\"_day\"] = data[\"train\"][\"merged_train\"][col].dt.day\n",
    "    data[\"train\"][\"merged_train\"][col+\"_quarter\"] = data[\"train\"][\"merged_train\"][col].dt.quarter\n",
    "    data[\"train\"][\"merged_train\"] = data[\"train\"][\"merged_train\"].drop([col], axis = 1)\n",
    "\n",
    "categoric_pipe = ColumnTransformer([\n",
    "                                    (\"ohe\", OneHotEncoder(), categoric_columns)],\n",
    "                                   remainder = \"passthrough\")\n",
    "x = categoric_pipe.fit_transform(data[\"train\"][\"merged_train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining train and dev sets\n",
    "\n",
    "It is necessary to train the model my measuring it's performance on not seen data (usually called dev set). \n",
    "We will assign 80% of the original train set data to our newly defined train set and the rest of 20% data to the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = shuffle(data[\"train\"][\"merged_train\"].drop([\"defaulted_loan\"], axis = 1), data[\"train\"][\"merged_train\"][\"defaulted_loan\"])\n",
    "# Assign 80% data to train set 20% data to dev set\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(x,\n",
    "                                                  y,\n",
    "                                                  test_size = 0.2)\n",
    "from imblearn.oversampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting pipelines to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Logistic Regression Model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "joaV89-_q4hI"
   },
   "source": [
    "# Error analysis\n",
    "\n",
    "In this section we further explore the instances in which the model made a wrong prediction to try to find patters, generate model improval propositions and measure the time investment / reward ratio of each to take a decision of the next step to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELI5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bla... por que ELI5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sigSCkyXq4hJ"
   },
   "source": [
    "# CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svEpL0cuq4hK",
    "outputId": "020ee590-3634-497b-ec30-1938ddd24aed"
   },
   "outputs": [],
   "source": [
    "demo_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1rQr_KTq4hR"
   },
   "outputs": [],
   "source": [
    "# Export as CSV\n",
    "demo_output.to_csv('growth_ds_challenge_luis_garcia.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "The problem definition was heavily influenced by\n",
    "\n",
    "[1] https://towardsdatascience.com/predicting-loan-repayment-5df4e0023e92\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deliverablenotebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
